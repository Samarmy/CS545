{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Sam Armstrong Assignment 4 CS545</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import sys\n",
    "import pandas\n",
    "\n",
    "import torch\n",
    "import mlutilities as ml  # for ml.draw\n",
    "import optimizers as opt  # for opt.sgd, opt.adam, and opt.scg\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import pickle, gzip\n",
    "\n",
    "import neuralnetworks as nn\n",
    "# import optimizers as opt  # from Lecture Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork_Convolutional():\n",
    "    \n",
    "    def __init__(self, n_channels_in_image, image_size,\n",
    "                 n_units_in_conv_layers, kernels_size_and_stride,\n",
    "                 n_units_in_fc_hidden_layers,\n",
    "                 classes, use_gpu=False, verbose=True):\n",
    "\n",
    "        if not isinstance(n_units_in_conv_layers, list):\n",
    "            raise Exception('n_units_in_conv_layers must be a list')\n",
    "\n",
    "        if not isinstance(n_units_in_fc_hidden_layers, list):\n",
    "            raise Exception('n_units_in_fc_hidden_layers must be a list')\n",
    "        \n",
    "        if use_gpu and not torch.cuda.is_available():\n",
    "            print('\\nGPU is not available. Running on CPU.\\n')\n",
    "            use_gpu = False\n",
    "\n",
    "        self.n_channels_in_image = n_channels_in_image\n",
    "        self.image_size = image_size \n",
    "        self.n_units_in_conv_layers = n_units_in_conv_layers\n",
    "        self.n_units_in_fc_hidden_layers = n_units_in_fc_hidden_layers\n",
    "        self.kernels_size_and_stride = kernels_size_and_stride\n",
    "        self.n_outputs = len(classes)\n",
    "        self.classes = np.array(classes)\n",
    "        self.use_gpu = use_gpu\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.n_conv_layers = len(self.n_units_in_conv_layers)\n",
    "        self.n_fc_hidden_layers = len(self.n_units_in_fc_hidden_layers)\n",
    "\n",
    "        # Build the net layers\n",
    "        self.nnet = torch.nn.Sequential()\n",
    "\n",
    "        # Add convolutional layers\n",
    "\n",
    "        n_units_previous = self.n_channels_in_image\n",
    "        output_size_previous = self.image_size\n",
    "        n_layers = 0\n",
    "        if self.n_conv_layers > 0:\n",
    "\n",
    "            for (n_units, kernel) in zip(self.n_units_in_conv_layers, self.kernels_size_and_stride):\n",
    "                n_units_previous, output_size_previous = self._add_conv2d_tanh(n_layers,\n",
    "                                        n_units_previous, output_size_previous, n_units, kernel)\n",
    "                n_layers += 1 # for text label in layer\n",
    "                \n",
    "        # A4.3 version moved following statement left one indent level\n",
    "        \n",
    "        self.nnet.add_module('flatten', torch.nn.Flatten())  # prepare for fc layers\n",
    "\n",
    "        n_inputs = output_size_previous ** 2 * n_units_previous\n",
    "        if self.n_fc_hidden_layers > 0:\n",
    "            for n_units in self.n_units_in_fc_hidden_layers:\n",
    "                n_inputs = self._add_fc_tanh(n_layers, n_inputs, n_units)\n",
    "                n_layers += 1\n",
    "\n",
    "        self.nnet.add_module(f'output_{n_layers}', torch.nn.Linear(n_inputs, self.n_outputs))\n",
    "\n",
    "        # Member variables for standardization\n",
    "        self.Xmeans = None\n",
    "        self.Xstds = None\n",
    "\n",
    "        if self.use_gpu:\n",
    "            self.nnet.cuda()\n",
    "\n",
    "        self.n_epochs = 0\n",
    "        self.error_trace = []\n",
    "\n",
    "    def _add_conv2d_tanh(self, n_layers, n_units_previous, output_size_previous,\n",
    "                   n_units, kernel_size_and_stride):\n",
    "        kernel_size, kernel_stride = kernel_size_and_stride\n",
    "        self.nnet.add_module(f'conv_{n_layers}', torch.nn.Conv2d(n_units_previous, n_units,\n",
    "                                                                 kernel_size, kernel_stride))\n",
    "        self.nnet.add_module(f'output_{n_layers}', torch.nn.Tanh())\n",
    "        output_size_previous = (output_size_previous - kernel_size) // kernel_stride + 1\n",
    "        n_units_previous = n_units                \n",
    "        return n_units_previous, output_size_previous\n",
    "    \n",
    "    def _add_fc_tanh(self, n_layers, n_inputs, n_units):\n",
    "        self.nnet.add_module(f'linear_{n_layers}', torch.nn.Linear(n_inputs, n_units))\n",
    "        self.nnet.add_module(f'output_{n_layers}', torch.nn.Tanh())\n",
    "        n_inputs = n_units\n",
    "        return n_inputs\n",
    "\n",
    "    def __repr__(self):\n",
    "        str = f'''{type(self).__name__}(\n",
    "                            n_channels_in_image={self.n_channels_in_image},\n",
    "                            image_size={self.image_size},\n",
    "                            n_units_in_conv_layers={self.n_units_in_conv_layers},\n",
    "                            kernels_size_and_stride={self.kernels_size_and_stride},\n",
    "                            n_units_in_fc_hidden_layers={self.n_units_in_fc_hidden_layers},\n",
    "                            classes={self.classes},\n",
    "                            use_gpu={self.use_gpu})'''\n",
    "\n",
    "        str += self.nnet\n",
    "        if self.n_epochs > 0:\n",
    "            str += f'\\n   Network was trained for {self.n_epochs} epochs that took {self.training_time:.4f} seconds.'\n",
    "            str += f'\\n   Final objective value is {self.error_trace[-1]:.3f}'\n",
    "        else:\n",
    "            str += '  Network is not trained.'\n",
    "        return str\n",
    "        \n",
    "    def _standardizeX(self, X):\n",
    "        result = (X - self.Xmeans) / self.XstdsFixed\n",
    "        result[:, self.Xconstant] = 0.0\n",
    "        return result\n",
    "\n",
    "    def _unstandardizeX(self, Xs):\n",
    "        return self.Xstds * Xs + self.Xmeans\n",
    "\n",
    "    def _setup_standardize(self, X, T):\n",
    "        if self.Xmeans is None:\n",
    "            self.Xmeans = X.mean(axis=0)\n",
    "            self.Xstds = X.std(axis=0)\n",
    "            self.Xconstant = self.Xstds == 0\n",
    "            self.XstdsFixed = copy.copy(self.Xstds)\n",
    "            self.XstdsFixed[self.Xconstant] = 1\n",
    "\n",
    "    def train(self, X, T, n_epochs, learning_rate=0.01):\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        if T.ndim == 1:\n",
    "            T = T.reshape((-1, 1))\n",
    "\n",
    "        _, T = np.where(T == self.classes)  # convert to labels from 0\n",
    "\n",
    "        self._setup_standardize(X, T)\n",
    "        X = self._standardizeX(X)\n",
    "\n",
    "        X = torch.tensor(X)\n",
    "        T = torch.tensor(T.reshape(-1))\n",
    "        if self.use_gpu:\n",
    "            X = X.cuda()\n",
    "            T = T.cuda()\n",
    "\n",
    "            \n",
    "        self.optimizer = torch.optim.Adam(self.nnet.parameters(), lr=learning_rate)\n",
    "        self.loss_F = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            Y = self.nnet(X)\n",
    "\n",
    "            error = self.loss_F(Y, T)\n",
    "            \n",
    "            if epoch % int(n_epochs/10) == 0 and self.verbose:\n",
    "                print(f'Epoch {epoch} error {error:.5f}')\n",
    "\n",
    "            error.backward()\n",
    "\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            self.error_trace.append(error)\n",
    "        \n",
    "        self.training_time = time.time() - start_time\n",
    "        \n",
    "    def get_error_trace(self):\n",
    "        return self.error_trace\n",
    "    \n",
    "    def _softmax(self, Y):\n",
    "        mx = Y.max()\n",
    "        expY = np.exp(Y - mx)\n",
    "        denom = expY.sum(axis=1).reshape((-1, 1)) + sys.float_info.epsilon\n",
    "        return expY / denom\n",
    "    \n",
    "    def use(self, X):\n",
    "        self.nnet.eval()  # turn off gradients and other aspects of training\n",
    "        X = self._standardizeX(X)\n",
    "        X = torch.tensor(X)\n",
    "        if self.use_gpu:\n",
    "            X = X.cuda()\n",
    "\n",
    "        Y = self.nnet(X)\n",
    "\n",
    "        if self.use_gpu:\n",
    "            Y = Y.cpu()\n",
    "        Y = Y.detach().numpy()\n",
    "        Yclasses = self.classes[Y.argmax(axis=1)].reshape((-1, 1))\n",
    "\n",
    "        return Yclasses, self._softmax(Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Simple Example with Squares and Diamonds</h2>\n",
    "\n",
    "Repeating the example from lecture notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 1, 20, 20), (1000, 1), (20, 1, 20, 20), (20, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_images(nEach):\n",
    "    images = np.zeros((nEach * 2, 1, 20, 20))  # nSamples, nChannels, rows, columns\n",
    "    radii = 3 + np.random.randint(10 - 5, size=(nEach * 2, 1))\n",
    "    centers = np.zeros((nEach * 2, 2))\n",
    "    for i in range(nEach * 2):\n",
    "        r = radii[i, 0]\n",
    "        centers[i, :] = r + 1 + np.random.randint(18 - 2 * r, size=(1, 2))\n",
    "        x = int(centers[i, 0])\n",
    "        y = int(centers[i, 1])\n",
    "        if i < nEach:\n",
    "            # squares\n",
    "            images[i, 0, x - r:x + r, y + r] = 1.0\n",
    "            images[i, 0, x - r:x + r, y - r] = 1.0\n",
    "            images[i, 0, x - r, y - r:y + r] = 1.0\n",
    "            images[i, 0, x + r, y - r:y + r + 1] = 1.0\n",
    "        else:\n",
    "            # diamonds\n",
    "            images[i, 0, range(x - r, x), range(y, y + r)] = 1.0\n",
    "            images[i, 0, range(x - r, x), range(y, y - r, -1)] = 1.0\n",
    "            images[i, 0, range(x, x + r + 1), range(y + r, y - 1, -1)] = 1.0\n",
    "            images[i, 0, range(x, x + r), range(y - r, y)] = 1.0\n",
    "            # images += np.random.randn(*images.shape) * 0.5\n",
    "            T = np.ones((nEach * 2, 1))\n",
    "            T[nEach:] = 2\n",
    "    return images.astype(np.float32), T.astype(np.int)\n",
    "\n",
    "Xtrain, Ttrain = make_images(500)\n",
    "Xtest, Ttest = make_images(10)\n",
    "\n",
    "Xtrain.shape, Ttrain.shape, Xtest.shape, Ttest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 error 0.52405\n",
      "Epoch 10 error 0.36662\n",
      "Epoch 15 error 0.24395\n",
      "Epoch 20 error 0.16086\n",
      "Epoch 25 error 0.11042\n",
      "Epoch 30 error 0.08320\n",
      "Epoch 35 error 0.06659\n",
      "Epoch 40 error 0.05520\n",
      "Epoch 45 error 0.04691\n",
      "Epoch 50 error 0.04066\n"
     ]
    }
   ],
   "source": [
    "nnet = NeuralNetwork_Convolutional(n_channels_in_image=Xtrain.shape[1],\n",
    "                                   image_size=Xtrain.shape[2],\n",
    "                                   n_units_in_conv_layers=[5], # , 5],\n",
    "                                   n_units_in_fc_hidden_layers=[2], # 10, 10],\n",
    "                                   classes=[1, 2],\n",
    "                                   kernels_size_and_stride=[[5, 2]], # , [4, 1]],\n",
    "                                   use_gpu=False)\n",
    "\n",
    "nnet.train(Xtrain, Ttrain, 50, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXhV5bn+8e+TnXkmJBCGYMIkAiJqRJzq0NqDYqGDVTjV0/Zo1bZWPda22smW/jrYetpqjx3UU1vbY53bUiechzoSKrMMIYCEAEmAkATIBM/vj73BiIEwZGUl2ffnuva193rX2jvP0pB7v2t4X3N3REQkfiWEXYCIiIRLQSAiEucUBCIicU5BICIS5xQEIiJxLjHsAg5Vfn6+FxcXh12GiEivMm/evFp3L+hoXa8LguLiYsrKysIuQ0SkVzGztftbp0NDIiJxTkEgIhLnAg0CM5tiZsvNrNzMbuxg/S/MbH7sscLM6oKsR0REPiiwcwRmFgHuAM4FKoG5Zjbb3Zfu2cbd/6vd9l8Bjg+qHhER6ViQPYJJQLm7V7h7C3A/MP0A288E/hJgPSIi0oEgg2AIsK7dcmWs7QPM7CigBHg+wHpERKQDQQaBddC2v6FOZwAPu/uuDj/I7AozKzOzspqami4rUEREgg2CSqCo3fJQoGo/287gAIeF3P1Ody9199KCgg7vh+jU2+9u5Zanlh3We0VE+rIgg2AuMMrMSswsmegf+9n7bmRmRwP9gNcDrIXF67fxmxdXsWJTQ5A/RkSk1wksCNy9DbgamAO8Azzo7kvMbJaZTWu36Uzgfg94hpx/G19IgsFjC/bXKRERiU+BDjHh7k8AT+zT9t19lr8XZA17DMhK5eSS/jy2aAP/de5ozDo6hSEiEn/i6s7iqRMGUVGznWUbdXhIRGSPuAqCKbHDQ48v3BB2KSIiPUZcBUF+ZgqnjOjP44s2EPApCRGRXiOuggBg6rGDWV27naUb6sMuRUSkR4i7IJgyvpBIgunwkIhITNwFQV5GMqfq8JCIyF5xFwQAF0wYxNrNO1hSpcNDIiJxGQQfHVtIYoLxmA4PiYjEZxD0y0jmtJH5PL6oSoeHRCTuxWUQQPTmsnVbdrJo/bawSxERCVXcBsG/jS0kKaLDQyIicRsEOelJnD4yn8cX6uohEYlvcRsEAFMnDGZ93U7mr6sLuxQRkdDEdRCcO3YgSRHdXCYi8S2ugyAnLYkPjSrgiUUb2L1bh4dEJD7FdRBA9Oqhqm1NvLF6c9iliIiEIu6D4Lzxg8jPTOF/ni8PuxQRkVDEfRCkJUe46szhvLZqM29WqFcgIvEn7oMA4JLJR1GQlcIvn10ZdikiIt1OQQCkJkW46swRvF6xmTfUKxCROKMgiPnMycNivYIVYZciItKtFAQxqUkRvnjmCN6o2MLrq9QrEJH4EWgQmNkUM1tuZuVmduN+trnIzJaa2RIzuy/Iejrz7ycPY4B6BSISZwILAjOLAHcA5wFjgZlmNnafbUYBNwGnufs44Lqg6jkYqUkRvnjWCN5cvYXXVtWGWYqISLcJskcwCSh39wp3bwHuB6bvs80XgDvcfSuAu1cHWM9BmTlpT69gpQajE5G4EGQQDAHWtVuujLW1NxoYbWavmtkbZjalow8ysyvMrMzMympqagIqNyo1KcKXzhrBW6t1rkBE4kOQQWAdtO37FTsRGAWcBcwE7jaz3A+8yf1Ody9199KCgoIuL3RfMyYNY2C2egUiEh+CDIJKoKjd8lCgqoNt/u7ure6+GlhONBhCFe0VjOStNVt4tVy9AhHp24IMgrnAKDMrMbNkYAYwe59t/gacDWBm+UQPFVUEWNNBu/ikIobkpjHrsSW07toddjkiIoEJLAjcvQ24GpgDvAM86O5LzGyWmU2LbTYH2GxmS4EXgK+5e4/4Cp6aFOF708axYlMj97y6OuxyREQCY73tGHhpaamXlZV128+7/I9zeW3VZp69/kwG56Z1288VEelKZjbP3Us7Wqc7iztx88fGsdudWf9YGnYpIiKBUBB0oigvna+cM4qnlmzkhWWh3+YgItLlFAQH4QtnDGdEQQY3z15CU+uusMsREelSCoKDkJyYwA+mj+fdLTv49Yurwi5HRKRLKQgO0qkj85k+cTC/fXEVq2u3h12OiEiXURAcgm+dfwwpiQl89++LdcexiPQZCoJDMCA7la9+dDSvrKzl8UUbwi5HRKRLKAgO0SWTj2Lc4Gxm/WMp9U2tYZcjInLEFASHKDGSwI8/eSy1jc389KllYZcjInLEFASHYcLQXD5/Wgl/fuNdytZsCbscEZEjoiA4TNefO5ohuWnc9OgiWto0KJ2I9F4KgsOUkZLIDz4+jpXVjfzuJd1bICK9l4LgCJwzZiBTJwziV8+Xs6qmMexyREQOi4LgCN38sbGkJCXwzUcX6d4CEemVFARHaEBWKt88/xjeXL2Fh8oqwy5HROSQKQi6wMWlRUwqzuOHT7xDTUNz2OWIiBwSBUEXSEgwfvTJ8exs2cWsxzRvgYj0LgqCLjJyQBZfOnsE/1hQxYvLNW+BiPQeCoIu9MWzRjCiIIPv/H0xO1s0b4GI9A4Kgi6UkhjhR584lnVbdvLL51aEXY6IyEFREHSxk4f35+LSIu5+ZTVLq+rDLkdEpFOBBoGZTTGz5WZWbmY3drD+c2ZWY2bzY4/Lg6ynu9x0/hj6pSdx018XsWu37i0QkZ4tsCAwswhwB3AeMBaYaWZjO9j0AXefGHvcHVQ93Sk3PZnvXDCWBevq+PMba8MuR0TkgILsEUwCyt29wt1bgPuB6QH+vB5l2nGDOWNUPj+bs5yN25rCLkdEZL+CDIIhwLp2y5Wxtn19yswWmtnDZlbU0QeZ2RVmVmZmZTU1NUHU2uXMjB9+/Fjadu/m5tmLwy5HRGS/ggwC66Bt3wPm/wCK3X0C8Czwx44+yN3vdPdSdy8tKCjo4jKDM6x/Otd+eDRzlmzi6SUbwy5HRKRDQQZBJdD+G/5QoKr9Bu6+2d33jMlwF3BigPWE4vIzShhTmMXNs5fQoKktRaQHCjII5gKjzKzEzJKBGcDs9huY2aB2i9OAdwKsJxRJsaktN9Y3ceuc5WGXIyLyAYEFgbu3AVcDc4j+gX/Q3ZeY2Swzmxbb7BozW2JmC4BrgM8FVU+Yjh/Wj8+eUsy9b6xl3tqtYZcjIvI+1tvG0C8tLfWysrKwyzhkjc1tfPTnL5GZmshjXzmD5ETdyyci3cfM5rl7aUfr9Neom2SmJPKDj49nxSZNbSkiPYuCoBt9+BhNbSkiPY+CoJvd/LGxpCYlcNOji9it4SdEpAdQEHSzPVNbvrV6Cw+Urev8DSIiAVMQhODik4o4uSSPHz3xDtX1Gn5CRMKlIAiBmfHjTx5Lc9tuvv8PTW0pIuFSEIRkeEEm15wzkscXbeCZpZvCLkdE4piCIERXfGgEYwqz+PbfFlGv4SdEJCQKghAlJyZwy6cmUNPQzE+eXBZ2OSISpxQEITuuKJf/PK2E+958lzcqNoddjojEIQVBD3D9R0dTlJfGjY8spKl1V9jliEicURD0AOnJifzkkxNYs3kHv3x2ZdjliEicURD0EKeNzOei0qHc9UoFi9dvC7scEYkjCoIe5FvnjyUvI5mvP7yQ1l27wy5HROKEgqAHyUlP4gfTx7F0Qz13vVIRdjkiEicUBD3MlPGDmDKukF8+u5IKjVAqIt1AQdADzZo+jtTEBL7xyEKNUCoigVMQ9EADslP5zgVjmbtmK/e+vibsckSkj1MQ9FAXnjiUM0cXcMtTy1m3ZUfY5YhIH6Yg6KH2jFAaSTC+8chCetvc0iLSeygIerDBuWl88/xjeG3VZu57692wyxGRPkpB0MPNnFTEqSP68+MnlrG+bmfY5YhIHxRoEJjZFDNbbmblZnbjAba70MzczEqDrKc3MjNu+dQEdrtz06OLdIhIRLpcYEFgZhHgDuA8YCww08zGdrBdFnAN8GZQtfR2RXnpfGPKGF5eUcPD8yrDLkdE+pggewSTgHJ3r3D3FuB+YHoH2/0A+CmgyXsP4NLJRzGpOI8fPLaUTZrnWES6UJBBMARY1265Mta2l5kdDxS5+2MH+iAzu8LMysysrKampusr7QUSEoxbLpxAc9tuvqlDRCLShYIMAuugbe9fLzNLAH4BfLWzD3L3O9291N1LCwoKurDE3qUkP4OvTxnDc8uqdYhIRLrMAYPAzC5p9/q0fdZd3clnVwJF7ZaHAlXtlrOA8cCLZrYGmAzM1gnjA/v8qcWcXJLHrH8s1VVEItIlOusRXN/u9a/2Wfefnbx3LjDKzErMLBmYAczes9Ldt7l7vrsXu3sx8AYwzd3LDq70+JSQYNz66ePY5c7XH16gsYhE5Ih1FgS2n9cdLb+Pu7cBVwNzgHeAB919iZnNMrNph1yp7FWUl863p47l1fLN/PnNtWGXIyK9XGIn630/rzta/uCb3Z8Antin7bv72faszj5P3jNzUhFzlmzkx08s44xRBZTkZ4Rdkoj0Up31CMaY2UIzW9Tu9Z7lo7uhPtmPPTeaJUWMGx5awC4dIhKRw9RZj+CYbqlCDkthTiqzpo/nugfmc9crFVx15oiwSxKRXuiAPQJ3X9v+ATQCJwD5sWUJ2fSJg5kyrpCfP72C5Rsbwi5HRHqhzi4ffczMxsdeDwIWE71a6E9mdl031CedMDN++InxZKUmcv2D82lu2xV2SSLSy3R2jqDE3RfHXn8eeMbdPwacTOeXj0o36Z+Zwo8/eSxLquq5dc7ysMsRkV6msyBobff6w8SuAHL3BmB3UEXJofvouEIunXwUd72ymheXV4ddjoj0Ip0FwToz+4qZfYLouYGnAMwsDUgKujg5NN+aegxHD8zihocWUNPQHHY5ItJLdBYElwHjgM8BF7t7Xax9MnBPgHXJYUhNinD7zONpaGrjqw/prmMROTidXTVU7e5Xuft0d3+6XfsL7n5r8OXJoTq6MIvvXDCWl1fU8PtXV4ddjoj0Age8j8DMZh9ovbtrqIge6DMnD+PlFTXc8tQyTi7pz7FDc8IuSUR6sM5uKDuF6JwCfyE6g9gBxxeSnsHM+OmFEzjvtle45v63eewrp5OR0tn/ahGJV52dIygEvkl0uOjbgHOBWnd/yd1fCro4OXy56cn84uKJrNm8nZtnLwm7HBHpwTo7R7DL3Z9y988SPUFcTnT+gK90S3VyRCYP789Xzh7Jw/MqeahsXedvEJG41OnxAjNLAaYCM4Fi4Hbg0WDLkq5yzYdHUbZ2K9/622KOGZTN+CE6XyAi79fZEBN/BF4jeg/B9939JHf/gbuv75bq5IglRhL41czj6Z+RzJV/msfW7S1hlyQiPUxn5wguBUYD1wKvmVl97NFgZvXBlyddoX9mCr+55ERqGpq59oH5GrJaRN6ns3MECe6eFXtkt3tkuXt2dxUpR25iUS7fmzaOl1fU8MtnV4Rdjoj0IJ31CKQPmTmpiItKh/Kr58t5ZummsMsRkR5CQRBHzIxZ08dz7JAcrn9gPqtrt4ddkoj0AAqCOJOaFOE3l5xAYsS46k/z2NHSFnZJIhIyBUEcGtovndtnHs/K6ga++qAGpxOJd4EGgZlNMbPlZlZuZjd2sP4qM1tkZvPN7J9mNjbIeuQ9Z4wq4KbzjuHJxRu57bmVYZcjIiEKLAjMLALcAZwHjAVmdvCH/j53P9bdJwI/BX4eVD3yQZefUcKFJw7ltudW8vjCDWGXIyIhCbJHMAkod/cKd28B7gemt9/A3dvfi5AB6BhFN9oz3/EJw3L56kPzWbx+W9gliUgIggyCIURHLt2jMtb2Pmb2ZTNbRbRHcE1HH2RmV5hZmZmV1dTUBFJsvEpJjPC7S0vJS0/minvLqG5oCrskEelmQQZBR0NWf+Abv7vf4e4jgG8A3+7og9z9TncvdffSgoKCLi5TCrJSuPM/Stm6o5Wr/jSP5rZdYZckIt0oyCCoBIraLQ8Fqg6w/f3AxwOsRw5g/JAc/vui4/jXu3V889HFuOsonUi8CDII5gKjzKzEzJKBGcD7Zjwzs1HtFqcCunwlROcfO4jrPjKKR/5Vye9ergi7HBHpJoFNW+XubWZ2NTAHiAC/d/clZjYLKHP32cDVZvYRoBXYCnw2qHrk4FxzzijKqxv5yZPLGJSTyvSJHzitIyJ9TKDzF7r7E8AT+7R9t93ra4P8+XLoEhKMWz99HNUNzdzw0AIKslI4dUR+2GWJSIB0Z7F8QGpShLsuLaW4fwZX/mkeyzZqxHGRvkxBIB3KSU/iD/85ifTkCJ+/Zy4btu0MuyQRCYiCQPZrSG4a93xuEg1NbXz+nrnUN7WGXZKIBEBBIAc0dnA2v73kRMqrG7ny3nm0tO0OuyQR6WIKAunU6aPy+emFE3i9YjPXPziftl0KA5G+JNCrhqTv+OQJQ6lpaObHTy4jkmD8/KKJRBI6unlcRHobBYEctCvPHEHbbudnc5YDKAxE+ggFgRySL589EoCfzVmOAf+tMBDp9RQEcsjahwEoDER6OwWBHJb39QwsejeywkCkd1IQyGH78tkjcXdufXoFAD+7cAKJEV2IJtLbKAjkiFx9zijMjJ/NWU5T6y5um3E8yYkKA5HeRP9i5Yh9+eyRfOeCsTy5eCNfuLeMnS2a2EakN1EQSJe47PQSfvLJY3l5ZQ2fvectGjQchUivoSCQLjNj0jBun3E8/1q7lc/c/SZbt7eEXZKIHAQFgXSpjx03mN9eciLLNjZw8Z2vU13fFHZJItIJBYF0uY+MHcgfPncSlVt3ctHvXmfdlh1hlyQiB6AgkECcOjKfP19+Mlu2t/Cp37ymyW1EejAFgQTmhGH9eOiqUzGDi377OnPXbAm7JBHpgIJAAnV0YRaPfPFU8jNTuOTuN3l26aawSxKRfSgIJHBD+6Xz0FWncHRhFlf+eR4Pz6sMuyQRaSfQIDCzKWa23MzKzezGDtZfb2ZLzWyhmT1nZkcFWY+Ep39mCvd9YTKTh+dxw0MLuPPlVWGXJCIxgQWBmUWAO4DzgLHATDMbu89mbwOl7j4BeBj4aVD1SPgyUxL5/edOYuqxg/jRE8v43uwlmu1MpAcIskcwCSh39wp3bwHuB6a338DdX3D3PdcWvgEMDbAe6QFSEiPcPvN4Lj+9hD+8tobP3vOWbjwTCVmQQTAEWNduuTLWtj+XAU8GWI/0EJEE49sXjOXWTx/H3NVbmX7Hq6zY1BB2WSJxK8gg6Ghweu9wQ7NLgFLgZ/tZf4WZlZlZWU1NTReWKGG68MSh3H/lZHa27uITd7zKM7qiSCQUQQZBJVDUbnkoULXvRmb2EeBbwDR3b+7og9z9TncvdffSgoKCQIqVcJwwrB//uPp0RgzI5Io/lfE/z6/EvcPvCyISkCCDYC4wysxKzCwZmAHMbr+BmR0P/I5oCFQHWIv0YIU5qTx45SlMP24wtz69giv/NE/nDUS6UWBB4O5twNXAHOAd4EF3X2Jms8xsWmyznwGZwENmNt/MZu/n46SPS02K8IuLJ/LtqcfwwvJqzrvtFV5bVRt2WSJxwXpbN7y0tNTLysrCLkMCtHj9Nq75y9us3rydL545gv86dzRJmgJT5IiY2Tx3L+1onf51SY8zfkgOj11zOheXFvHrF1dx4W9eY03t9rDLEumzFATSI6UnJ/KTT03g1585gdW125l6+ys8VLZOJ5JFAqAgkB7t/GMH8dR1H2LckBy+9vBCLv9jGZs02Y1Il1IQSI83ODeNv3xhMt+eegz/LK/l3J+/xCPzKtU7EOkiCgLpFSIJxuVnDOep6z7E6IFZfPWhBVym3oFIl1AQSK9Skp/BA1eewncuGMtrq6K9A507EDkyCgLpdSIJxmWnl/DktdHewdceXsiMO9/QeEUih0lBIL1WSX4GD155Cj/6xLEs29jA+be9wg8fX0pjc1vYpYn0KgoC6dUSEox/P3kYL9xwFp86YSh3vbKaD//3izy2sEqHi0QOkoJA+oS8jGRuuXACj34pOj/y1fe9zaX/+xbLNtaHXZpIj6cgkD7lhGH9mH316cyaPo6FlXWcd9sr3PDQAqrqdoZdmkiPpbGGpM+q29HCr19cxR9eWwPA508r5ktnjiQnPSncwkRCcKCxhhQE0udVbt3Bz59ZwV/fXk92ahJXnz2SS085itSkSNiliXQbBYEIsLSqnlueWsZLK2oYkJXCVWeOYOakYaQlKxCk71MQiLTz+qrN3PbcCt6o2EJ+ZgpXfmg4n5k8jPTkxLBLEwmMgkCkA29WbOZXz5fzz/Ja8jKS+cIZw7n0lKPITFEgSN+jIBA5gHlrt3D7c+W8tKKGrNREZpxUxH+cUkxRXnrYpYl0GQWByEFYsK6Ou/+5micWbcDdmTK+kMtOL+GEYf0ws7DLEzkiCgKRQ1BVt5N7X1/LfW+upb6pjeOG5vC504o5b/wgXWkkvZaCQOQw7Ghp45F5ldzz6hoqareTnZrIx48fwkWlRYwfkhN2eSKHREEgcgR273beqNjM/XPX8dSSjbS07Wb8kGwuLi1i2sQh5KTpBjXp+RQEIl2kbkcLf59fxQNz17F0Qz3JiQmcNbqAqRMG8eFjBuqKI+mxQgsCM5sC3AZEgLvd/Sf7rP8Q8EtgAjDD3R/u7DMVBNJTLF6/jYfnVfLk4g1sqm8mJTGBc8YMYOqEQZwzZoDuS5AeJZQgMLMIsAI4F6gE5gIz3X1pu22KgWzgBmC2gkB6o927nXnvbuWxBVU8sXgjNQ3NpCYlcPrIfM4eM4BzxgxgUE5a2GVKnDtQEAT5lWUSUO7uFbEi7gemA3uDwN3XxNbtDrAOkUAlJBgnFedxUnEe3/3YOOau2cKTizbw3LJqnn2nGoAxhVmcEwuFiUW5JEY08K/0HEEGwRBgXbvlSuDkw/kgM7sCuAJg2LBhR16ZSEAiCcbk4f2ZPLw/35vmlFc38vyyap5fVs3vXq7g1y+uIislkZOH53HqiHxOHdmf0QOySEjQfQoSniCDoKPf7MM6DuXudwJ3QvTQ0JEUJdJdzIxRA7MYNTCLK88cwbadrfxzZS3/LK/l9VW1e3sL/TOSmTwiGh6lR/Vj9MAsIgoG6UZBBkElUNRueShQFeDPE+nRctKSmDphEFMnDAJgfd1OXiuv5fVVm3l1VS2PL9wAQFZqIicM68dJxf048ag8JhblaoRUCVSQQTAXGGVmJcB6YAbw7wH+PJFeZUhuGp8uLeLTpUW4O+u27GTumi2Urd3KvLVbuPXpGiB6uOnogVkcV5TDcUNzOa4ol1EDMnWeQbpM0JePnk/08tAI8Ht3/6GZzQLK3H22mZ0E/BXoBzQBG9193IE+U1cNSbyo29HCv97dyr/W1rGgso4F6+qob2oDIC0pwvgh2YwbnMO4wdHnUQMzSVI4yH7ohjKRPsDdWbN5BwvW1TF/XR0LK+t4Z0MDO1t3AZAcSWB0YSbjB+cwpjCLowuzGVOYRb+M5JArl55AQSDSR+3a7ayu3c6Sqm0srapncdU2llTVU7ejde82A7JSOLowizGF0RPXIwdkMnJAJtmpGhojnoR1H4GIBCySYHv/sE+fOASI9hyqG5pZvrGB5RsbWLaxgeWb6rn39bU0t713y86ArJS97x05IJOS/AxK8jMYnJOmy1njjIJApI8xMwZmpzIwO5UPjS7Y275rt7Nuyw7Kqxspr2lk5abo86P/Wk9jc9ve7ZITEyjun05JfgbF+RkclZfBUf3TGZaXzuDcNF3a2gcpCETiRCTBKI79cf8IA/e27+lBrK7dvvdRUbOdVTXbeX5ZNa273jt8nBQxhuSmMax/BkX90hjaL52ivNhzvzTyMpI1iU8vpCAQiXPtexCTh/d/37pdu52N9U2s3byddzfvYO2WHbHn7SysrHvfuQiIXs00pF8ag3PTGJKbxpDcVAbnvrc8IDuFlETdE9HTKAhEZL8iCRb7g57GqSM+uL6hqZX1dTtZt2UnlVt3sG7LTqrqdlK1bSdLq7ZR29jygffkZyYzKCeNwpxUBuekMjAnlcJYEA3MTqUwJ1XDeXcz/dcWkcOWlZrEmMIkxhRmd7i+qXUXVXU7WV+3kw3bmthQ18TG+ujrdzfv4M2KzXvvjWgvIznCwOxUCrJSGJCdyoCslOgjO4UBWdH2/MwUctOSdGK7CygIRCQwqUkRhhdkMrwgc7/bbG9uY1N9E5vqm2PPTWysb6K6vpnqhiYWVtZRXd+8936J9hITjP6ZyeRnplCQlUL/jBTyM5Ppn5lM/4yUvevyMpLJy0jWnNP7oSAQkVBlpCR2GhbuTmNzG9UNzVTXN1Pb+N6jpqGZ2sYWahqaWbmpkZrGZlraOh7ZPiM5Qr+MZPrHgqFfRjJ56dHn3PQk8tKTyU1Ppl9GEv3Sk8lJS4qL8FAQiEiPZ2ZkpSaRlZrEiAMEBrwXGpsbW9i8vZmahha27mhhy/b3P2obW1ixqZGtO1rY0fLB3sYeaUkRctOTyEl7Lxxy0pLITU8iO/a8py07NfaclkR2amKvGQ9KQSAifUr70CjOzzio9zS17qJuRytbd7SwdXsLW3e0UrezhbodrdTtiD3vjL6uqG3cu7y/nsceGckRstOSyEpNJDs19hxbzkp97zk7NZGs1EQyU/a0JZKVkkRGSqRbwkRBICJxLzUpQmFOhMKc1EN6X1PrLrbtbKVuRyv1Ta3U72xl287oc31T297XDU1t1De1UtPYTEXt9r3rd+3ufIiftKQImamJZKUkct25o5l23ODD3c39UhCIiBym1KQIqUnRK5wOlbvT1LqbhqZoKDQ0RQOjoamN7c1tNDS30djURmNzK43N0fa89GAGEFQQiIiEwMxIS46QlhxhQMdX33ab3nEmQ0REAqMgEBGJcwoCEZE4pyAQEYlzCgIRkTinIBARiXMKAhGROKcgEBGJc+be+S3OPYmZ1QBrD/Pt+UBtF5bTW8TrfkP87rv2O74czH4f5e4FHa3odUFwJMyszN1Lw66ju8XrfkP87rv2O74c6X7r0JCISJxTEIiIxLl4C4I7wy4gJPG63xC/+679ji9HtN9xdY5AREQ+KN56BCIisg8FgYhInIubIDCzKWa23MzKzd0U7NUAAATwSURBVOzGsOsJipn93syqzWxxu7Y8M3vGzFbGnvuFWWMQzKzIzF4ws3fMbImZXRtr79P7bmapZvaWmS2I7ff3Y+0lZvZmbL8fMLNgprYKmZlFzOxtM3ssttzn99vM1pjZIjObb2ZlsbYj+j2PiyAwswhwB3AeMBaYaWZjw60qMH8ApuzTdiPwnLuPAp6LLfc1bcBX3f0YYDLw5dj/476+783AOe5+HDARmGJmk4FbgF/E9nsrcFmINQbpWuCddsvxst9nu/vEdvcOHNHveVwEATAJKHf3CndvAe4HpodcUyDc/WVgyz7N04E/xl7/Efh4txbVDdx9g7v/K/a6gegfhyH08X33qMbYYlLs4cA5wMOx9j633wBmNhSYCtwdWzbiYL/344h+z+MlCIYA69otV8ba4sVAd98A0T+YwICQ6wmUmRUDxwNvEgf7Hjs8Mh+oBp4BVgF17t4W26Sv/r7/Evg6sDu23J/42G8HnjazeWZ2RaztiH7P42XyeuugTdfN9kFmlgk8Alzn7vXRL4l9m7vvAiaaWS7wV+CYjjbr3qqCZWYXANXuPs/MztrT3MGmfWq/Y05z9yozGwA8Y2bLjvQD46VHUAkUtVseClSFVEsYNpnZIIDYc3XI9QTCzJKIhsD/ufujsea42HcAd68DXiR6jiTXzPZ80euLv++nAdPMbA3RQ73nEO0h9PX9xt2rYs/VRIN/Ekf4ex4vQTAXGBW7oiAZmAHMDrmm7jQb+Gzs9WeBv4dYSyBix4f/F3jH3X/eblWf3nczK4j1BDCzNOAjRM+PvABcGNusz+23u9/k7kPdvZjov+fn3f0z9PH9NrMMM8va8xr4KLCYI/w9j5s7i83sfKLfGCLA7939hyGXFAgz+wtwFtFhaTcBNwN/Ax4EhgHvAp92931PKPdqZnY68AqwiPeOGX+T6HmCPrvvZjaB6MnBCNEvdg+6+ywzG070m3Ie8DZwibs3h1dpcGKHhm5w9wv6+n7H9u+vscVE4D53/6GZ9ecIfs/jJghERKRj8XJoSERE9kNBICIS5xQEIiJxTkEgIhLnFAQiInFOQSASY2a7YiM67nl02QB1ZlbcfkRYkZ4kXoaYEDkYO919YthFiHQ39QhEOhEb//2W2Lj/b5nZyFj7UWb2nJktjD0Pi7UPNLO/xuYIWGBmp8Y+KmJmd8XmDXg6dicwZnaNmS2Nfc79Ie2mxDEFgch70vY5NHRxu3X17j4J+B+id6gTe32vu08A/g+4PdZ+O/BSbI6AE4AlsfZRwB3uPg6oAz4Va78ROD72OVcFtXMi+6M7i0VizKzR3TM7aF9DdPKXitjAdhvdvb+Z1QKD3L011r7B3fPNrAYY2n5og9jQ2M/EJg7BzL4BJLn7/zOzp4BGokOB/K3d/AIi3UI9ApGD4/t5vb9tOtJ+zJtdvHeObirRGfROBOa1Gz1TpFsoCEQOzsXtnl+PvX6N6MiXAJ8B/hl7/RzwRdg7aUz2/j7UzBKAInd/gegkK7nAB3olIkHSNw+R96TFZvra4yl333MJaYqZvUn0y9PMWNs1wO/N7GtADfD5WPu1wJ1mdhnRb/5fBDbs52dGgD+bWQ7RiVV+EZtXQKTb6ByBSCdi5whK3b027FpEgqBDQyIicU49AhGROKcegYhInFMQiIjEOQWBiEicUxCIiMQ5BYGISJz7//+XwT0Me83vAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(nnet.get_error_trace())\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 out of 20 test samples correctly classified.  Training took 1.216 seconds.\n"
     ]
    }
   ],
   "source": [
    "Yclasses, Y = nnet.use(Xtest)\n",
    "\n",
    "print(f'{np.sum(Ttest == Yclasses)} out of {Ttest.shape[0]} test samples correctly classified.', end='')\n",
    "print(f'  Training took {nnet.training_time:.3f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_layer_output(nnet, X_sample, layer):\n",
    "    outputs = []\n",
    "    reg = nnet.nnet[layer * 2].register_forward_hook(\n",
    "        lambda self, i, o: outputs.append(o))\n",
    "    nnet.use(X_sample)\n",
    "    reg.remove()\n",
    "    output = outputs[0]\n",
    "\n",
    "    n_units = output.shape[1]\n",
    "    nplots = int(np.sqrt(n_units)) + 1\n",
    "    for unit in range(n_units):\n",
    "        plt.subplot(nplots, nplots, unit+1)\n",
    "        plt.imshow(output[0, unit, :, :].detach(),cmap='binary')\n",
    "        plt.axis('off')\n",
    "    return output\n",
    "\n",
    "def show_layer_weights(nnet, layer):\n",
    "    W = nnet.nnet[layer*2].weight.detach()\n",
    "    n_units = W.shape[0]\n",
    "    nplots = int(np.sqrt(n_units)) + 1\n",
    "    for unit in range(n_units):\n",
    "        plt.subplot(nplots, nplots, unit + 1)\n",
    "        plt.imshow(W[unit, 0, :, :], cmap='binary')\n",
    "        plt.axis('off')\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 19.5, 19.5, -0.5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAC80lEQVR4nO3dMQ6DMBAAwTji/192HhAUGoI3YaaE5prVScgyY875AHqeqwcA9okTosQJUeKEKHFC1Hbw3qdc+L6x99DmhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTog6un2PHzPG7kVuXOyMfxDZnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiHJ878bOOGJ2J1cfjbQ5IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiNpWD8A6Y4zVI/CBzQlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihCjH9/7MnHP1CJzE5oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oSo7eD9uGQK4I3NCVHihChxQpQ4IUqcECVOiHoBkpEO2KDMU+0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_sample = Xtest[0:1, :, :, :]\n",
    "plt.imshow(X_sample[0, 0, :, :], cmap='binary')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_layer_output(nnet, X_sample, 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_layer_weights(nnet, 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>MNIST Digits</h2>\n",
    "\n",
    "Investigate the application of your code to the classification of MNIST digits, which you may download from this site. http://deeplearning.net/tutorial/gettingstarted.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://deeplearning.net/data/mnist/mnist.pkl.gz\n",
    "\n",
    "# Load the dataset\n",
    "with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
    "    train_set, valid_set, test_set = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (50000,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = train_set[0]\n",
    "Ttrain = train_set[1]\n",
    "Xtrain.shape, Ttrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Xtrain[0, :].reshape(28, 28)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.imshow(Xtrain[i, :].reshape(28, 28), cmap='binary')\n",
    "    plt.title(Ttrain[i])\n",
    "    plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 1, 28, 28),\n",
       " (50000, 1),\n",
       " (10000, 1, 28, 28),\n",
       " (10000, 1),\n",
       " (10000, 1, 28, 28),\n",
       " (10000, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = train_set[0].reshape(50000, 1, 28, 28)\n",
    "Ttrain = train_set[1].reshape(50000, 1)\n",
    "Xvalid = valid_set[0].reshape(10000, 1, 28, 28)\n",
    "Tvalid = valid_set[1].reshape(10000, 1)\n",
    "Xtest = test_set[0].reshape(10000, 1, 28, 28)\n",
    "Ttest = test_set[1].reshape(10000, 1)\n",
    "Xtrain.shape, Ttrain.shape, Xvalid.shape, Tvalid.shape, Xtest.shape, Ttest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(conv_layers, hidden_layers, kernels_size_and_stride, epochs, learning_rate=0.1, use_gpu=True):\n",
    "    nnet1 = NeuralNetwork_Convolutional(n_channels_in_image=Xtrain.shape[1],\n",
    "                                   image_size=Xtrain.shape[2],\n",
    "                                   n_units_in_conv_layers=conv_layers,\n",
    "                                   n_units_in_fc_hidden_layers=hidden_layers, \n",
    "                                   classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                                   kernels_size_and_stride=kernels_size_and_stride,\n",
    "                                   use_gpu=use_gpu)\n",
    "    nnet1.train(Xtrain, Ttrain, epochs, learning_rate=learning_rate)\n",
    "    YclassesTrain, Ytrain = nnet1.use(Xtrain)\n",
    "    YclassesValid, Yvalid = nnet1.use(Xvalid)\n",
    "    YclassesTest, Ytest = nnet1.use(Xtest)\n",
    "    print(f'{np.sum(Ttrain == YclassesTrain)/Ttrain.shape[0]*100:.2f}% or {np.sum(Ttrain == YclassesTrain)} out of {Ttrain.shape[0]} training samples correctly classified.')\n",
    "    print(f'{np.sum(Tvalid == YclassesValid)/Tvalid.shape[0]*100:.2f}% or {np.sum(Tvalid == YclassesValid)} out of {Tvalid.shape[0]} validation samples correctly classified.')\n",
    "    print(f'{np.sum(Ttest == YclassesTest)/Ttest.shape[0]*100:.2f}% or {np.sum(Ttest == YclassesTest)} out of {Ttest.shape[0]} testing samples correctly classified.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model 1 conv_layers=[10], fc_hidden_layers=[10], kernels_size_and_stride=[[5, 5]], epochs = 100</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU is not available. Running on CPU.\n",
      "\n",
      "Epoch 10 error 0.61152\n",
      "Epoch 20 error 0.46129\n",
      "Epoch 30 error 0.38732\n",
      "Epoch 40 error 0.33704\n",
      "Epoch 50 error 0.30652\n",
      "Epoch 60 error 0.27948\n",
      "Epoch 70 error 0.26672\n",
      "Epoch 80 error 0.24467\n",
      "Epoch 90 error 0.23163\n",
      "Epoch 100 error 0.23009\n",
      "93.49% or 46746 out of 50000 training samples correctly classified.\n",
      "92.72% or 9272 out of 10000 validation samples correctly classified.\n",
      "91.77% or 9177 out of 10000 testing samples correctly classified.\n"
     ]
    }
   ],
   "source": [
    "testModel([10], [10], [[5, 5]], 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model 2 conv_layers=[10], fc_hidden_layers=[10], kernels_size_and_stride=[[5, 3]], epochs = 100</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU is not available. Running on CPU.\n",
      "\n",
      "Epoch 10 error 0.76459\n",
      "Epoch 20 error 0.56048\n",
      "Epoch 30 error 0.45822\n",
      "Epoch 40 error 0.39175\n",
      "Epoch 50 error 0.34950\n",
      "Epoch 60 error 0.31874\n",
      "Epoch 70 error 0.29615\n",
      "Epoch 80 error 0.27928\n",
      "Epoch 90 error 0.26348\n",
      "Epoch 100 error 0.25301\n",
      "92.79% or 46394 out of 50000 training samples correctly classified.\n",
      "92.02% or 9202 out of 10000 validation samples correctly classified.\n",
      "91.55% or 9155 out of 10000 testing samples correctly classified.\n"
     ]
    }
   ],
   "source": [
    "testModel([10], [10], [[5, 3]], 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model 3 conv_layers=[10], fc_hidden_layers=[20], kernels_size_and_stride=[[5, 3]], epochs = 100</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU is not available. Running on CPU.\n",
      "\n",
      "Epoch 10 error 0.54104\n",
      "Epoch 20 error 0.37822\n",
      "Epoch 30 error 0.29806\n",
      "Epoch 40 error 0.25040\n",
      "Epoch 50 error 0.22347\n",
      "Epoch 60 error 0.20252\n",
      "Epoch 70 error 0.18604\n",
      "Epoch 80 error 0.17434\n",
      "Epoch 90 error 0.16121\n",
      "Epoch 100 error 0.15606\n",
      "95.82% or 47912 out of 50000 training samples correctly classified.\n",
      "94.07% or 9407 out of 10000 validation samples correctly classified.\n",
      "93.32% or 9332 out of 10000 testing samples correctly classified.\n"
     ]
    }
   ],
   "source": [
    "testModel([10], [20], [[5, 3]], 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model 4 conv_layers=[10, 10], fc_hidden_layers=[20], kernels_size_and_stride=[[5, 3], [4, 2]], epochs = 200</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU is not available. Running on CPU.\n",
      "\n",
      "Epoch 20 error 0.38405\n",
      "Epoch 40 error 0.23864\n",
      "Epoch 60 error 0.18163\n",
      "Epoch 80 error 0.15155\n",
      "Epoch 100 error 0.13665\n",
      "Epoch 120 error 0.13015\n",
      "Epoch 140 error 0.11798\n",
      "Epoch 160 error 0.10055\n",
      "Epoch 180 error 0.09713\n",
      "Epoch 200 error 0.10670\n",
      "96.62% or 48309 out of 50000 training samples correctly classified.\n",
      "94.07% or 9407 out of 10000 validation samples correctly classified.\n",
      "93.87% or 9387 out of 10000 testing samples correctly classified.\n"
     ]
    }
   ],
   "source": [
    "testModel([10, 10], [20], [[5, 3], [4, 2]], 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model 5 conv_layers=[10, 20], fc_hidden_layers=[20], kernels_size_and_stride=[[5, 3], [4, 2]], epochs = 200</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU is not available. Running on CPU.\n",
      "\n",
      "Epoch 20 error 0.33973\n",
      "Epoch 40 error 0.21018\n",
      "Epoch 60 error 0.15715\n",
      "Epoch 80 error 0.13116\n",
      "Epoch 100 error 0.12564\n",
      "Epoch 120 error 0.09730\n",
      "Epoch 140 error 0.08414\n",
      "Epoch 160 error 0.09531\n",
      "Epoch 180 error 0.07120\n",
      "Epoch 200 error 0.07905\n",
      "97.68% or 48840 out of 50000 training samples correctly classified.\n",
      "93.92% or 9392 out of 10000 validation samples correctly classified.\n",
      "93.76% or 9376 out of 10000 testing samples correctly classified.\n"
     ]
    }
   ],
   "source": [
    "testModel([10, 20], [20], [[5, 3], [4, 2]], 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model 6 conv_layers=[10, 20, 30], fc_hidden_layers=[20], kernels_size_and_stride=[[5, 3], [4, 2], [3, 1]], epochs = 200</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU is not available. Running on CPU.\n",
      "\n",
      "Epoch 20 error 0.49307\n",
      "Epoch 40 error 0.26076\n",
      "Epoch 60 error 0.17106\n",
      "Epoch 80 error 0.12782\n",
      "Epoch 100 error 0.10416\n",
      "Epoch 120 error 0.08806\n",
      "Epoch 140 error 0.08228\n",
      "Epoch 160 error 0.06727\n",
      "Epoch 180 error 0.09260\n",
      "Epoch 200 error 0.05774\n",
      "98.63% or 49313 out of 50000 training samples correctly classified.\n",
      "94.06% or 9406 out of 10000 validation samples correctly classified.\n",
      "93.52% or 9352 out of 10000 testing samples correctly classified.\n"
     ]
    }
   ],
   "source": [
    "testModel([10, 20, 30], [20], [[5, 3], [4, 2], [3, 1]], 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model 7 conv_layers=[10, 20, 30, 40], fc_hidden_layers=[20], kernels_size_and_stride=[[5, 3], [4, 2], [3, 1], [1, 1]], epochs = 200</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU is not available. Running on CPU.\n",
      "\n",
      "Epoch 20 error 0.39970\n",
      "Epoch 40 error 0.20011\n",
      "Epoch 60 error 0.13291\n",
      "Epoch 80 error 0.10043\n",
      "Epoch 100 error 0.09438\n",
      "Epoch 120 error 0.06277\n",
      "Epoch 140 error 0.04507\n",
      "Epoch 160 error 0.03623\n",
      "Epoch 180 error 0.10348\n",
      "Epoch 200 error 0.04930\n",
      "98.78% or 49391 out of 50000 training samples correctly classified.\n",
      "95.02% or 9502 out of 10000 validation samples correctly classified.\n",
      "94.82% or 9482 out of 10000 testing samples correctly classified.\n"
     ]
    }
   ],
   "source": [
    "testModel([10, 20, 30, 40], [20], [[5, 3], [4, 2], [3, 1], [1, 1]], 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model 8 conv_layers=[10, 20, 30, 40], fc_hidden_layers=[20], kernels_size_and_stride=[[5, 3], [4, 2], [3, 1], [1, 2]], epochs = 300</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU is not available. Running on CPU.\n",
      "\n",
      "Epoch 20 error 0.43636\n",
      "Epoch 40 error 0.22165\n",
      "Epoch 60 error 0.14856\n",
      "Epoch 80 error 0.11110\n",
      "Epoch 100 error 0.11395\n",
      "Epoch 120 error 0.07644\n",
      "Epoch 140 error 0.05833\n",
      "Epoch 160 error 0.11937\n",
      "Epoch 180 error 0.05984\n",
      "Epoch 200 error 0.04157\n",
      "99.06% or 49532 out of 50000 training samples correctly classified.\n",
      "94.27% or 9427 out of 10000 validation samples correctly classified.\n",
      "93.81% or 9381 out of 10000 testing samples correctly classified.\n"
     ]
    }
   ],
   "source": [
    "testModel([10, 20, 30, 40], [20], [[5, 3], [4, 2], [3, 1], [1, 2]], 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model 9 conv_layers=[10, 20, 30, 40], fc_hidden_layers=[20], kernels_size_and_stride=[[5, 3], [4, 2], [3, 2], [1, 2]], epochs = 200</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU is not available. Running on CPU.\n",
      "\n",
      "Epoch 20 error 0.51659\n",
      "Epoch 40 error 0.27944\n",
      "Epoch 60 error 0.19233\n",
      "Epoch 80 error 0.15432\n",
      "Epoch 100 error 0.12091\n",
      "Epoch 120 error 0.20833\n",
      "Epoch 140 error 0.10589\n",
      "Epoch 160 error 0.07356\n",
      "Epoch 180 error 0.07615\n",
      "Epoch 200 error 0.05765\n",
      "98.59% or 49293 out of 50000 training samples correctly classified.\n",
      "93.45% or 9345 out of 10000 validation samples correctly classified.\n",
      "93.06% or 9306 out of 10000 testing samples correctly classified.\n"
     ]
    }
   ],
   "source": [
    "testModel([10, 20, 30, 40], [20], [[5, 3], [4, 2], [3, 2], [1, 2]], 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model 10 conv_layers=[10, 20, 30, 40], fc_hidden_layers=[10], kernels_size_and_stride=[[5, 3], [4, 2], [3, 2], [1, 2]], epochs = 200</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU is not available. Running on CPU.\n",
      "\n",
      "Epoch 20 error 0.55951\n",
      "Epoch 40 error 0.28231\n",
      "Epoch 60 error 0.18529\n",
      "Epoch 80 error 0.13797\n",
      "Epoch 100 error 0.10863\n",
      "Epoch 120 error 0.09639\n",
      "Epoch 140 error 0.07315\n",
      "Epoch 160 error 0.13423\n",
      "Epoch 180 error 0.07818\n",
      "Epoch 200 error 0.05673\n",
      "98.76% or 49379 out of 50000 training samples correctly classified.\n",
      "93.34% or 9334 out of 10000 validation samples correctly classified.\n",
      "92.96% or 9296 out of 10000 testing samples correctly classified.\n"
     ]
    }
   ],
   "source": [
    "testModel([10, 20, 30, 40], [10], [[5, 3], [4, 2], [3, 2], [1, 2]], 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "Starting from model 1 I changed at least one of the parameters each time I created a new model. The models mostly increase in success rate from model 1 to model 10. This is what the incremental changes to each model looks like this.\n",
    "\n",
    "1. conv = [10], hidden = [10], kernel stride = [[5, 5]], epochs 100\n",
    "2. kernel stride = [[5, 3]]\n",
    "3. hidden = [20]\n",
    "4. conv = [10, 10] kernel stride = [[5, 3], [4, 2]] epoch 200\n",
    "5. conv = [10, 20]\n",
    "6. conv = [10, 20, 30] kernel stride = [[5, 3], [4, 2], [3, 1]]\n",
    "7. conv = [10, 20, 30, 40] kernel stride = [[5, 3], [4, 2], [3, 1], [1, 1]]\n",
    "8. kernel stride = [[5, 3], [4, 2], [3, 1], [1, 2]]\n",
    "9. kernel stride = [[5, 3], [4, 2], [3, 2], [1, 2]]\n",
    "10. hidden = [10]\n",
    "\n",
    "Increasing the number of convolutional layers seemed to imporve the performance (testing, validation, and training success rate). Increasing the stride and epochs also seemed to improve the performance. The number of hidden layers seemed less important and increasing the number of hidden layers to more than one or the units to more than 10 didn't seem to affect the success rate. The training success rate was the easiest to manipulate (compared to validation and testing success rate) which could give a maximum result of 99%. The validation and testing data was more difficult to increase and seemed to respond less to the changes to the CNN structure, each giving a max success rate of 95%. One change that did seem to directly affect the validation and testing success rate was increasing the number of epochs. Overall it seems like a more complex CNN is better on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 error 1.02210\n",
      "Epoch 40 error 0.40151\n",
      "Epoch 60 error 0.19175\n",
      "Epoch 80 error 0.11041\n",
      "Epoch 100 error 0.07138\n",
      "Epoch 120 error 0.04964\n",
      "Epoch 140 error 0.03669\n",
      "Epoch 160 error 0.02846\n",
      "Epoch 180 error 0.02292\n",
      "Epoch 200 error 0.01917\n"
     ]
    }
   ],
   "source": [
    "cnnet = NeuralNetwork_Convolutional(n_channels_in_image=Xtrain.shape[1],\n",
    "                                   image_size=Xtrain.shape[2],\n",
    "                                   n_units_in_conv_layers=[10, 20, 30, 40],\n",
    "                                   n_units_in_fc_hidden_layers=[10], \n",
    "                                   classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                                   kernels_size_and_stride=[[5, 3], [4, 2], [3, 2], [1, 2]],\n",
    "                                   use_gpu=False)\n",
    "cnnet.train(Xtrain, Ttrain, 200, learning_rate=0.01)\n",
    "YclassesTrain, Ytrain = cnnet.use(Xtrain)\n",
    "YclassesValid, Yvalid = cnnet.use(Xvalid)\n",
    "YclassesTest, Ytest = cnnet.use(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAACvCAYAAABnwrxKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAMX0lEQVR4nO3d32uX9R/G8Wu2H5ZOU5elBdOZrJosmk2bWaQHUiAhVEhHSXZQnXUSEUF10kEgRCedCf04KQbWSSUaIxMXZqItnT9yljVc/sgtzek26/sPXNf34z3k+70/9nwcXo7ts3v3Lm/2+rzf75p//vlHAPBvN+X//QIAoAwoQwAQZQgAkihDAJBEGQKAJMoQACRJtf/tH3t7ewu972bKFN+tKb/hhhsKffyVK1cK5cuWLaux/1ASW7Zssdc3XZe6ujqbT5061eYNDQ02//vvv21+6dKlQvnatWtLe317enoK3btF78WUJxMTEzZPP4tHHnmktNf26NGj9trW1PiXnK5tba2vn/Tx6W2A6dqmXmhpabEvlCdDABBlCACSKEMAkEQZAoCkCgOUpL6+3uZjY2M2P3XqlP/i4Q+op0+fLvT5z58/b/Nly5bZvCzSH+HTH4q3bdtm8yNHjth8+vTpNr/zzjtt3tzcbPO7777b5tUoDaF+/vlnm6d7MQ0LZs+ebfPh4WGbP/jggzYvs3Tfpt/nixcv2jxd27/++svmaSCSfi8efvhhm7e0tNicJ0MAEGUIAJIoQwCQRBkCgCTKEAAkTXKanCZpaTqUlnMtXrzY5vPnz7f5vffea/OTJ0/avFrddNNNNt+wYYPNp02bVihPn//333+3+eXLl21eZukeHR8ft3lHR4fN02Szra2t0OtJ13zfvn2FPk8ZpGubJvVpCpwsWLDA5q2trTZ/7LHHbJ7u54QnQwAQZQgAkihDAJBEGQKAJMoQACRVmCanNbJpunjXXXfZ/MYbb7T54cOHbb5w4cJCHz86OmrzefPm2bwsim5WOTIyYvM///yz0NcdHBy0edoMNr2eJUuWFPq6/0tp09QkfY/p3v3mm29sXnQD4rTOvxqlKfOiRYtsnvYUSPdheidA6qOi9wBPhgAgyhAAJFGGACCJMgQASZQhAEiqME1O05h0lF/Rqe6MGTNsvn//fpvffvvtNk9HZVartJNwmqbNnDnT5un67t692+ZpJ/G0JrTM0mQzTfDThD2tk02fJ+3q3tjYaPPr6d4tes27urpsnnZuP3r0qM3TGvyik3qeDAFAlCEASKIMAUASZQgAkihDAJBUYZqcppopT9PnNKlLZ8yeOXPG5kNDQzZP5/2WXZq+pTxd32PHjtl8z549Nv/tt99s/uKLL9o8XfcyK3oN09rhdG3TLspNTU02Tztdp0lrmRW9b9O67/Tuk3StDhw4YPN0DvisWbNsnvBkCACiDAFAEmUIAJIoQwCQRBkCgKRJnpucpj0XLlyw+cDAgM3TDs2dnZ02T2ui09m2ZZcmiekc6J07d9o8TTafeeYZm7/99ts2Tz+nNH0us3Rta2v9LX/w4EGbp+nzmjVrbJ52/961a5fNq/FM6iRN5E+cOGHzNKlPa+1XrVpV6OumnbQTngwBQJQhAEiiDAFAEmUIAJIoQwCQVGGanNYatre32/y5556z+dNPP23zjo4Om6cpc5oaV+P6Tknq7++3+auvvmrzvr4+m6edxNMUuLu72+YXL160eTrHtsxWr15t85deesnm69evt3maDqfdmL/44gubp3dCVOO1feGFF2y+detWmz/77LM2f+2112ye1hSn3/+0A3yaMic8GQKAKEMAkEQZAoAkyhAAJFGGACBJqqnWSSwAXEs8GQKAKEMAkEQZAoAkyhAAJFGGACCJMgQASZQhAEiiDAFAEmUIAJIq7Ge4YcMGuzwl7XOY8rSXWzp5LO1DlvL0dT/44AP/DyWxZ8+eQte3qLS66FqtOurs7Czt9V2+fHmhb/JaXfN0Txe1e/fu0l7b/v7+a9ILU6b4Z7HUF0nqhfSzaG1ttS+IJ0MAEGUIAJIoQwCQRBkCgKQKA5T0B870B8u9e/fa/JZbbrF5+sPqHXfcYfNz587ZfNOmTTYvu6IDpzlz5tj80qVLNr9w4YLN08E6n3/+uc0feughm1ejy5cv2/zXX3+1eX19vc2nTp1q84ULF9p85cqVNh8dHbV5NUqDuaIHvKU89U76GaX7v7W11eY8GQKAKEMAkEQZAoAkyhAAJFGGACCpwjQ5SdPO1atX23z27Nk2f/TRR21+/Phxm/f09Nj8s88+s/nLL79s87JI0/q0jKi7u9vmLS0tNr/ttttsPm/ePJs///zzNk9TvDJLk810zZ944gmbp3v3xIkTNk+T0A8//NDmTU1NNq9GqReam5ttPjY2ZvObb77Z5undF9OnT7f50NCQzROeDAFAlCEASKIMAUASZQgAkihDAJBUYZpcdCKX1g739fXZfObMmTbfsWOHzY8cOWLzn376yeZlnyYnad3rk08+afOdO3fafPny5TZP1+vkyZM2T9PttA63Gm3fvt3m06ZNs3ljY6PN0zsh6urqbJ6mz2WWeiG96yCtnW9oaLD5/v37bZ6m0oODgzZPrzO9y4InQwAQZQgAkihDAJBEGQKAJMoQACRVmCYX3Yk57Wg7PDxs819++cXmp0+ftvmiRYtsfj3tFizlaX3apTldl08++cTm9913n83T5DTtGFxm6d5NE8Z0T6d3SCxevNjm6WeU7ulqVPRY1fT7mabJ99xzj83Tu0zS/Z92wE54MgQAUYYAIIkyBABJlCEASKIMAUDSJKfJaSI3MTFh8zTVeeedd2z+1FNP2Xzt2rU2/+ijj2xedkWncuPj4zafMWOGzZcuXWrz77//3uadnZ02r8b1s0Wln0WaDm/ZssXmXV1dNm9vb7f5wMDAVby66pb6Ik3YU4/Mnz+/0Men9eAJT4YAIMoQACRRhgAgiTIEAEmUIQBImuRO12kKtHfvXpunaefrr79u87Sj7bfffmvz2tpJHf/8f5cmmClPuyun657WhC9ZsuQqXl11S/fumTNnbJ7u6ba2Nps//vjjhT7PH3/8YfO0JrrM0rVN5yCn/NSpUzafO3euzdNE/uzZszYfGRmxecKTIQCIMgQASZQhAEiiDAFAEmUIAJIqTJPT+aXr1q2z+aeffmrzr776qlD+8ccf2zyd35vOXy67zZs32/zdd9+1+XvvvWfzlStX2nzBggU2T+cmp+le0TXUZXD48GGbpwnj+++/b/N0nvJ3331n8/Pnz9s87SJedP1sGaSdq++//36bv/nmmzbfuHGjzdMO2IcOHbJ5msgXvW95MgQAUYYAIIkyBABJlCEASKIMAUCSVJPWGQLAvwlPhgAgyhAAJFGGACCJMgQASZQhAEiiDAFAEmUIAJIoQwCQRBkCgKQK+xmuWLGi0PKUtK9Y0TyddjcxMVEo//rrr0u9EV9XV5e9vmnfxrRaqOgqoilT/P+BKU96e3tLfX2BIngyBABRhgAgiTIEAEmUIQBIqjBAKfqH+XTQ0NDQkM3TQU633nqrzdesWWPz4eHhq3h15ZMGJekgmzlz5ti8v7/f5kUPIUo/jxUrVtgcuJ7wZAgAogwBQBJlCACSKEMAkEQZAoCkCtPk5MqVKzZfv369zdMUtLe31+atra02HxwctHl9fb3Nyy5N68fGxmw+d+5cmy9dutTmBw4csHljY6PNz507Z/Pt27fb/K233rI5UI14MgQAUYYAIIkyBABJlCEASKIMAUDSJNcmp81Ue3p6bL5q1Sqb//jjjzbv6+uzeVNTk80bGhpsXnbp+o6Ojtp8x44dNm9vb7f58ePHbf7DDz/YvLm52eazZs2yOXA94ckQAEQZAoAkyhAAJFGGACCJMgQASRWmyWnH5SStqf3yyy9tvnHjRpt3d3fbfN++fTZ/4IEHruLVlU+6vmnKPDIyYvO0w3hag5x2DN+2bZvNmSbj34AnQwAQZQgAkihDAJBEGQKAJMoQACRNcqfr+Mlq/acbHx+3+aZNm2ze1tZm85aWFpun84fLLk2N0/eTru/Zs2dtnqb7aQ1y2mG86PnZQDXiyRAARBkCgCTKEAAkUYYAIIkyBABJk9zpOp2bfOjQIZunnag7Ojpsns4BPnbsmM3Tecpll6bGaU1xuu7p3Og0fU/nLydF16gD1YgnQwAQZQgAkihDAJBEGQKAJMoQACRVmCavW7fO5q+88orN33jjDZsPDQ3ZfGBgwOZbt261eV1dnc2r9dzk9Lp37dpl882bN9s8nTOddhg/ePCgzdMUO62JBq4nPBkCgChDAJBEGQKAJMoQACRRhgAgSaphF2MA4MkQACRRhgAgiTIEAEmUIQBIogwBQBJlCACSpP8APjC/jlLhSwUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_layer_output(cnnet, Xtrain, 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_layer_weights(cnnet, 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "The output of the convolutional looks like its either capturing straight lines (the top of the 5 or the bottom of the 5) or curved lines (the rightside/bottom curve of the 5). The layer weights seemed to be focused on the bottom area (the line on the bottom of the five), the right middle area (the rightside/bottom curve of the 5), or the top area (the line on the top of the five). It looks like the layer weights focus on one or two areas in the picture and if a line appears in that area it is accentuated in the output images of the convalutional layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 error 0.87895\n",
      "Epoch 40 error 0.33125\n",
      "Epoch 60 error 0.15939\n",
      "Epoch 80 error 0.09495\n",
      "Epoch 100 error 0.06356\n",
      "Epoch 120 error 0.04603\n",
      "Epoch 140 error 0.03497\n",
      "Epoch 160 error 0.02775\n",
      "Epoch 180 error 0.02297\n",
      "Epoch 200 error 0.01948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "208.53940796852112"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnnet_non_gpu = NeuralNetwork_Convolutional(n_channels_in_image=Xtrain.shape[1],\n",
    "                                   image_size=Xtrain.shape[2],\n",
    "                                   n_units_in_conv_layers=[10, 20, 30, 40],\n",
    "                                   n_units_in_fc_hidden_layers=[10], \n",
    "                                   classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                                   kernels_size_and_stride=[[5, 3], [4, 2], [3, 2], [1, 2]],\n",
    "                                   use_gpu=False)\n",
    "cnnet_non_gpu.train(Xtrain, Ttrain, 200, learning_rate=0.01)\n",
    "cnnet_non_gpu.training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 error 0.92195\n",
      "Epoch 40 error 0.35166\n",
      "Epoch 60 error 0.16741\n",
      "Epoch 80 error 0.10402\n",
      "Epoch 100 error 0.07130\n",
      "Epoch 120 error 0.05246\n",
      "Epoch 140 error 0.04040\n",
      "Epoch 160 error 0.03226\n",
      "Epoch 180 error 0.02632\n",
      "Epoch 200 error 0.02180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26.813615560531616"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnnet_gpu = NeuralNetwork_Convolutional(n_channels_in_image=Xtrain.shape[1],\n",
    "                                   image_size=Xtrain.shape[2],\n",
    "                                   n_units_in_conv_layers=[10, 20, 30, 40],\n",
    "                                   n_units_in_fc_hidden_layers=[10], \n",
    "                                   classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                                   kernels_size_and_stride=[[5, 3], [4, 2], [3, 2], [1, 2]],\n",
    "                                   use_gpu=True)\n",
    "cnnet_gpu.train(Xtrain, Ttrain, 200, learning_rate=0.01)\n",
    "cnnet_gpu.training_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Without the gpu the time was ~208 seconds and with the gpu it was ~26 seconds. Running a convalutional layers seems really computationally expensive especially when the kernel size and stride are small. This is likely because the CNN has to look at more sub-areas of the picture which requires alot of matrix calculations. So running matrix calculations on a gpu really speeds up the training of a CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================= Code Execution =======================\n",
      "\n",
      "Extracting python code from notebook named 'Armstrong-A3.ipynb' and storing in notebookcode.py\n",
      "Removing all statements that are not function or class defs or import statements.\n",
      "\n",
      "Testing if your NeuralNetwork_Convolutional can learn to classify a small \n",
      "subset of hand_drawn 0, 1, and 2 digits.\n",
      "\n",
      "import numpy as np\n",
      "import pickle, gzip\n",
      "\n",
      "# Load the dataset\n",
      "with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
      "    train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
      "Xtest = test_set[0]\n",
      "traini = [3,  10,  13,  25,  28,  55,  69,  71, 101, 126, 2,   5,  14,  29,  31,  37,  39,  40,  46,  57, 1,  35,  38,  43,  47,  72,  77,  82, 106, 119]\n",
      "testi = [136, 148, 157, 183, 188, 192, 194, 215, 246, 269,  74,  89,  94, 96, 107, 135, 137, 143, 145, 154, 147, 149, 172, 174, 186, 199, 208, 221, 222, 225]\n",
      "Xtrain = test_set[0][traini, :].reshape(-1, 1, 28, 28)\n",
      "Ttrain = test_set[1][traini].reshape(-1, 1)\n",
      "Xtest = test_set[0][testi, :].reshape(-1, 1, 28, 28)\n",
      "Ttest = test_set[1][testi].reshape(-1, 1)\n",
      "\n",
      "torch.random.manual_seed(42)\n",
      "\n",
      "nnet = NeuralNetwork_Convolutional(n_channels_in_image=Xtrain.shape[1],\n",
      "                                   image_size=Xtrain.shape[2],\n",
      "                                   n_units_in_conv_layers=[5, 5],\n",
      "                                   kernels_size_and_stride=[[5, 3], [4, 2]],\n",
      "                                   n_units_in_fc_hidden_layers=[10],\n",
      "                                   classes=[0, 1, 2],\n",
      "                                   use_gpu=False)\n",
      "\n",
      "nnet.train(Xtrain, Ttrain, 20, learning_rate=0.01)\n",
      "Yclasses, Y = nnet.use(Xtest)\n",
      "n_correct = (Yclasses == Ttest).sum()\n",
      "print(f'{n_correct} out of {Ttest.shape[0]} samples, or {n_correct/Ttest.shape[0]*100:.2f} percent.')\n",
      "\n",
      "Epoch 2 error 1.03157\n",
      "Epoch 4 error 0.87973\n",
      "Epoch 6 error 0.69274\n",
      "Epoch 8 error 0.51123\n",
      "Epoch 10 error 0.37162\n",
      "Epoch 12 error 0.27101\n",
      "Epoch 14 error 0.20077\n",
      "Epoch 16 error 0.15003\n",
      "Epoch 18 error 0.11277\n",
      "Epoch 20 error 0.08578\n",
      "27 out of 30 samples, or 90.00 percent.\n",
      "\n",
      "--- 80/80 points. Returned correct value of 27.\n",
      "\n",
      "Testing \n",
      "errors = nnet.get_error_trace()\n",
      "\n",
      "\n",
      "--- 10/10 points. Returned correct number of errors in error_trace.\n",
      "\n",
      "======================================================================\n",
      "cs545 Execution Grade is 90 / 90\n",
      "======================================================================\n",
      "\n",
      " __ / 10 You show results for at least 10 different runs having various\n",
      "values for number of layers, units, and epochs for modeling MNIST data.\n",
      "You must show percent correct for train, validation and test sets for each run.\n",
      "Discuss your results. \n",
      "\n",
      "======================================================================\n",
      "cs545 FINAL GRADE is  _  / 100\n",
      "======================================================================\n",
      "\n",
      "Extra Credit:\n",
      "1. For one of your runs, display the output images of your convolutional layers \n",
      "   and the weights for those layers.  Discuss what you see.  Describe why the\n",
      "   displayed weight patterns result in the output images of the first convolutional\n",
      "   layer.\n",
      "2. Make at least one of your runs on a workstation with a GPU and run with use_gpu=True.\n",
      "   Also run it with use_gpu=False.  Discuss the differences in training times.\n",
      "\n",
      "cs545 EXTRA CREDIT is 0 / 2\n"
     ]
    }
   ],
   "source": [
    "# !rm A4grader.zip\n",
    "# !rm A4grader.py\n",
    "# !wget https://www.cs.colostate.edu/~anderson/cs545/notebooks/A4grader.zip\n",
    "# !unzip A4grader.zip\n",
    "# %run -i A4grader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
